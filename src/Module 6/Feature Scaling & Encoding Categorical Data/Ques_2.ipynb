{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5: Label Encoding vs One-Hot Encoding\n",
    "# Task: Show the difference between Label Encoding and One-Hot Encoding on the Titanic dataset for the 'Sex' feature.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 6: Combining Feature Scaling Techniques\n",
    "# Task: Demonstrate combining Min-Max Scaling and Standardization for the same datasetand explain the results.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 7: Handling Multiple Categorical Features\n",
    "# Task: Handle multiple categorical features ('Sex', 'Embarked') from the Titanic dataset using One-Hot Encoding.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 8: Ordinal Encoding for Ranked Categories\n",
    "# Task: Ordinal encode 'Pclass' (Passenger class) from the Titanic dataset considering passenger class as a ranked feature.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 9: Impact of Scaling on Different Algorithms\n",
    "# Task: Investigate the impact of different scaling techniques on a decision tree model and compare it with a SVM.\n",
    "\n",
    "\n",
    "\n",
    "# Question 10: Custom Transformations for Categorical Features\n",
    "# Task: Implement a custom transformation function for encoding high cardinality categorical features efficiently.\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "# Load Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "titanic = pd.read_csv(url)\n",
    "\n",
    "# Question 5: Label Encoding vs One-Hot Encoding on 'Sex'\n",
    "le = LabelEncoder()\n",
    "titanic['Sex_label'] = le.fit_transform(titanic['Sex'])\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False, drop='if_binary')\n",
    "sex_ohe = ohe.fit_transform(titanic[['Sex']])\n",
    "df_sex_ohe = pd.DataFrame(sex_ohe, columns=ohe.get_feature_names_out(['Sex']))\n",
    "\n",
    "print(\"Label Encoding (first 5):\")\n",
    "print(titanic[['Sex', 'Sex_label']].head())\n",
    "print(\"\\nOne-Hot Encoding (first 5):\")\n",
    "print(df_sex_ohe.head(), \"\\n\")\n",
    "\n",
    "# Question 6: Combining Min-Max Scaling and Standardization on numeric features ('Age', 'Fare')\n",
    "num_cols = ['Age', 'Fare']\n",
    "df_numeric = titanic[num_cols].copy()\n",
    "\n",
    "# Fill missing Age with median for demonstration\n",
    "df_numeric['Age'].fillna(df_numeric['Age'].median(), inplace=True)\n",
    "\n",
    "scaler_minmax = MinMaxScaler()\n",
    "scaled_minmax = scaler_minmax.fit_transform(df_numeric)\n",
    "\n",
    "scaler_standard = StandardScaler()\n",
    "scaled_standard = scaler_standard.fit_transform(scaled_minmax)\n",
    "\n",
    "df_combined_scaled = pd.DataFrame(scaled_standard, columns=num_cols)\n",
    "print(\"Combined Min-Max Scaling then Standardization (first 5 rows):\")\n",
    "print(df_combined_scaled.head(), \"\\n\")\n",
    "\n",
    "# Question 7: One-Hot Encoding 'Sex' and 'Embarked'\n",
    "titanic['Embarked'].fillna('Missing', inplace=True)\n",
    "ct = ColumnTransformer(transformers=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'), ['Sex', 'Embarked'])\n",
    "], remainder='drop')\n",
    "\n",
    "encoded = ct.fit_transform(titanic)\n",
    "ohe_feature_names = ct.named_transformers_['onehot'].get_feature_names_out(['Sex', 'Embarked'])\n",
    "df_ohe_multi = pd.DataFrame(encoded.toarray(), columns=ohe_feature_names)\n",
    "print(\"One-Hot Encoding of 'Sex' and 'Embarked' (first 5 rows):\")\n",
    "print(df_ohe_multi.head(), \"\\n\")\n",
    "\n",
    "# Question 8: Ordinal Encoding for 'Pclass' (ranked)\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['3', '2', '1']])  # Assuming 1 is highest class, 3 is lowest\n",
    "pclass_str = titanic['Pclass'].astype(str).values.reshape(-1, 1)\n",
    "titanic['Pclass_ordinal'] = ordinal_encoder.fit_transform(pclass_str)\n",
    "print(\"Ordinal Encoding of 'Pclass' (first 5 rows):\")\n",
    "print(titanic[['Pclass', 'Pclass_ordinal']].head(), \"\\n\")\n",
    "\n",
    "# Question 9: Impact of scaling on Decision Tree vs SVM\n",
    "X = titanic[['Age', 'Fare']].copy()\n",
    "X['Age'].fillna(X['Age'].median(), inplace=True)\n",
    "y = titanic['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Decision Tree (no scaling needed)\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "pred_dt = dt.predict(X_test)\n",
    "acc_dt = accuracy_score(y_test, pred_dt)\n",
    "\n",
    "# SVM without scaling\n",
    "svm = SVC(random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "acc_svm_no_scale = accuracy_score(y_test, svm.predict(X_test))\n",
    "\n",
    "# SVM with Standard Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "svm_scaled = SVC(random_state=42)\n",
    "svm_scaled.fit(X_train_scaled, y_train)\n",
    "acc_svm_scaled = accuracy_score(y_test, svm_scaled.predict(X_test_scaled))\n",
    "\n",
    "print(f\"Decision Tree Accuracy: {acc_dt}\")\n",
    "print(f\"SVM Accuracy without scaling: {acc_svm_no_scale}\")\n",
    "print(f\"SVM Accuracy with Standard Scaling: {acc_svm_scaled}\\n\")\n",
    "\n",
    "# Question 10: Custom Transformer for high cardinality categorical features\n",
    "class HighCardinalityEncoder(TransformerMixin):\n",
    "    def __init__(self, top_n=10):\n",
    "        self.top_n = top_n\n",
    "        self.top_categories_ = {}\n",
    "        self.ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for col in X.columns:\n",
    "            counts = X[col].value_counts()\n",
    "            self.top_categories_[col] = counts.nlargest(self.top_n).index.tolist()\n",
    "        X_reduced = X.apply(lambda col: col.where(col.isin(self.top_categories_[col.name]), other='Other'))\n",
    "        self.ohe.fit(X_reduced)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_reduced = X.apply(lambda col: col.where(col.isin(self.top_categories_[col.name]), other='Other'))\n",
    "        return self.ohe.transform(X_reduced)\n",
    "\n",
    "# Example usage on 'Cabin' (high cardinality, many missing)\n",
    "titanic['Cabin'].fillna('Missing', inplace=True)\n",
    "high_card_feat = titanic[['Cabin']]\n",
    "\n",
    "encoder = HighCardinalityEncoder(top_n=5)\n",
    "encoder.fit(high_card_feat)\n",
    "encoded_cabin = encoder.transform(high_card_feat)\n",
    "\n",
    "print(\"Custom encoded high cardinality 'Cabin' feature shape:\", encoded_cabin.shape)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
