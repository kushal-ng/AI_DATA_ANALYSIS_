{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance of Data Cleaning\n",
    "\n",
    "# 1. Missing Values: Missing data points in a dataset can lead to biased results.\n",
    "#     Task 1: Load a dataset and identify which columns have missing values.\n",
    "#     Task 2: Replace missing values in a dataset with the column mean or mode.\n",
    "#     Task 3: Compare model performance with and without handling missing values.\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Task 1: Load a dataset and identify which columns have missing values\n",
    "data = load_diabetes()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "# Introduce missing values artificially for demonstration\n",
    "df.loc[5:10, 'bmi'] = np.nan\n",
    "df.loc[20:25, 'bp'] = np.nan\n",
    "\n",
    "# Identify missing values\n",
    "missing_info = df.isnull().sum()\n",
    "print(\"Missing Values per Column:\\n\", missing_info[missing_info > 0])\n",
    "\n",
    "# Task 2: Replace missing values in a dataset with the column mean\n",
    "df_cleaned = df.fillna(df.mean())\n",
    "\n",
    "# Task 3: Compare model performance with and without handling missing values\n",
    "\n",
    "# Original target\n",
    "target = pd.Series(data.target)\n",
    "\n",
    "# Prepare data by dropping rows with missing values\n",
    "df_dropped = df.dropna()\n",
    "target_dropped = target[df_dropped.index]\n",
    "\n",
    "# Train-test split for dropped data\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(df_dropped, target_dropped, test_size=0.2, random_state=42)\n",
    "model1 = LinearRegression().fit(X_train1, y_train1)\n",
    "pred1 = model1.predict(X_test1)\n",
    "print(\"\\nR2 score without filling missing values:\", r2_score(y_test1, pred1))\n",
    "\n",
    "# Train-test split for mean-filled data\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(df_cleaned, target, test_size=0.2, random_state=42)\n",
    "model2 = LinearRegression().fit(X_train2, y_train2)\n",
    "pred2 = model2.predict(X_test2)\n",
    "print(\"R2 score after filling missing values with mean:\", r2_score(y_test2, pred2))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Duplicate Data: Repeated data points can skew analysis and model results.\n",
    "#     Task 1: Identify and remove duplicate entries from a dataset using a programming language or tool.\n",
    "#     Task 2: Document the before-and-after dataset shape to understand the impact of duplicates.\n",
    "#     Task 3: Explain to a classmate how duplicate data can affect prediction accuracy.\n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "# Sample dataset with duplicate entries\n",
    "data = {\n",
    "    'id': [1, 2, 2, 3, 4, 4, 4, 5],\n",
    "    'name': ['Alice', 'Bob', 'Bob', 'Charlie', 'David', 'David', 'David', 'Eve'],\n",
    "    'score': [85, 90, 90, 95, 80, 80, 80, 88]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Task 1: Identify duplicates\n",
    "duplicates = df.duplicated()\n",
    "print(\"Duplicate rows (True indicates duplicate):\\n\", duplicates)\n",
    "\n",
    "# Task 2: Remove duplicates and compare shapes\n",
    "print(\"\\nOriginal dataset shape:\", df.shape)\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "print(\"Dataset shape after removing duplicates:\", df_no_duplicates.shape)\n",
    "\n",
    "# Task 3: Explanation (as comment)\n",
    "# Duplicate data can bias the model by over-representing certain observations,\n",
    "# which may lead to inaccurate or skewed predictions because the model\n",
    "# might treat duplicates as additional evidence rather than repeated data points.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Incorrect Data Types: Data stored in incorrect formats can lead to parsing errors or incorrect analysis.\n",
    "#     Task 1: Convert a column of string numbers to integers in a dataset.\n",
    "#     Task 2: Identify and correct columns with inconsistent data types in a dataset.\n",
    "#     Task 3: Discuss why correct data types are critical for feature engineering.\n",
    "import pandas as pd\n",
    "\n",
    "# Sample dataset with incorrect data types\n",
    "data = {\n",
    "    'id': ['1', '2', '3', '4'],         # numbers as strings\n",
    "    'age': [25, '30', '35', 40],        # mixed types: int and string\n",
    "    'salary': ['50000', '60000', '70000', '80000']  # numbers as strings\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Task 1: Convert a column of string numbers to integers\n",
    "df['id'] = df['id'].astype(int)\n",
    "print(\"After converting 'id' to integers:\\n\", df['id'])\n",
    "\n",
    "# Task 2: Identify columns with inconsistent data types\n",
    "for col in df.columns:\n",
    "    types = df[col].apply(type).unique()\n",
    "    print(f\"Column '{col}' has data types: {types}\")\n",
    "\n",
    "# Correct inconsistent data types in 'age' column\n",
    "df['age'] = pd.to_numeric(df['age'], errors='coerce').astype('Int64')\n",
    "print(\"\\nAfter correcting 'age' column data types:\\n\", df['age'])\n",
    "\n",
    "# Task 3: Explanation (as comment)\n",
    "# Correct data types are critical for feature engineering because many\n",
    "# operations, like mathematical transformations, aggregations, or scaling,\n",
    "# require numeric types. Incorrect types may cause errors or inaccurate features.\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Outliers & Inconsistencies: Irregularities in data can mislead statistical analysis and model predictions.\n",
    "#     Task 1: Visualize a dataset and identify outliers using a boxplot.\n",
    "#     Task 2: Remove or adjust outliers and re-analyze the dataset.\n",
    "#     Task 3: Research and report on a technique for handling outliers effectively.\n",
    "    \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample dataset with potential outliers\n",
    "data = {\n",
    "    'age': [22, 25, 30, 24, 100, 28, 26, 27, 29, 24]  # 100 is an outlier\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Task 1: Visualize dataset and identify outliers using a boxplot\n",
    "plt.boxplot(df['age'])\n",
    "plt.title(\"Boxplot of Age\")\n",
    "plt.show()\n",
    "\n",
    "# Task 2: Remove outliers using IQR method\n",
    "Q1 = df['age'].quantile(0.25)\n",
    "Q3 = df['age'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df_no_outliers = df[(df['age'] >= lower_bound) & (df['age'] <= upper_bound)]\n",
    "\n",
    "# Re-analyze: Show boxplot after removing outliers\n",
    "plt.boxplot(df_no_outliers['age'])\n",
    "plt.title(\"Boxplot of Age After Removing Outliers\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Dataset after removing outliers:\\n\", df_no_outliers)\n",
    "\n",
    "# Task 3: Explanation (as comment)\n",
    "# One common technique for handling outliers is the IQR method,\n",
    "# which detects outliers as values outside 1.5*IQR range from Q1 and Q3.\n",
    "# Outliers can be removed, capped, or transformed depending on the use case.\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
