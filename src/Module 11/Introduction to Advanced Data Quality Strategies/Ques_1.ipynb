{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Data Profiling to Understand Data Quality\n",
    "**Description**: Use basic statistical methods to profile a dataset and identify potential quality issues.\n",
    "\n",
    "**Steps**:\n",
    "1. Load the dataset using pandas in Python.\n",
    "2. Understand the data by checking its basic statistics.\n",
    "3. Identify null values.\n",
    "4. Check unique values for categorical columns.\n",
    "5. Review outliers using box plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code from here\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Load dataset\n",
    "# Example dataset: Titanic dataset from seaborn (or replace with your own CSV)\n",
    "import seaborn as sns\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# Step 2: Basic statistics\n",
    "print(\"Basic Statistical Summary:\\n\", df.describe(include='all'))\n",
    "\n",
    "# Step 3: Identify null values\n",
    "print(\"\\nMissing Values per Column:\\n\", df.isnull().sum())\n",
    "\n",
    "# Step 4: Unique values for categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\nUnique values in '{col}': {df[col].unique()}\")\n",
    "\n",
    "# Step 5: Review outliers with box plots for numeric columns\n",
    "numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.title(f\"Box plot of {col}\")\n",
    "    plt.boxplot(df[col].dropna())\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Implement Simple Data Validation\n",
    "**Description**: Write a Python script to validate the data types and constraints of each column in a dataset.\n",
    "\n",
    "**Steps**:\n",
    "1. Define constraints for each column.\n",
    "2. Validate each column based on its constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code from here\n",
    "import pandas as pd\n",
    "\n",
    "# Sample dataset\n",
    "data = {\n",
    "    'age': [25, 30, -1, 40],          # age should be non-negative integer\n",
    "    'gender': ['M', 'F', 'F', 'O'],  # gender should be in set {'M', 'F'}\n",
    "    'income': [50000, 60000, 70000, None]  # income should be positive and non-null\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 1: Define constraints\n",
    "constraints = {\n",
    "    'age': lambda x: x.apply(lambda v: isinstance(v, int) and v >= 0),\n",
    "    'gender': lambda x: x.isin(['M', 'F']),\n",
    "    'income': lambda x: x.notnull() & (x > 0)\n",
    "}\n",
    "\n",
    "# Step 2: Validate each column and collect errors\n",
    "errors = []\n",
    "for col, check_func in constraints.items():\n",
    "    if col in df.columns:\n",
    "        valid_mask = check_func(df[col])\n",
    "        if not valid_mask.all():\n",
    "            invalid_indices = df.index[~valid_mask].tolist()\n",
    "            errors.append(f\"Column '{col}' failed validation at rows: {invalid_indices}\")\n",
    "    else:\n",
    "        errors.append(f\"Column '{col}' is missing in the dataset.\")\n",
    "\n",
    "if errors:\n",
    "    print(\"Validation Errors:\")\n",
    "    for err in errors:\n",
    "        print(\"-\", err)\n",
    "else:\n",
    "    print(\"All columns passed validation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Detect Missing Data Patterns\n",
    "**Description**: Analyze and visualize missing data patterns in a dataset.\n",
    "\n",
    "**Steps**:\n",
    "1. Visualize missing data using a heatmap.\n",
    "2. Identify patterns in missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code from here\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample dataset with missing values\n",
    "data = {\n",
    "    'age': [25, None, 35, 40, None],\n",
    "    'gender': ['M', 'F', None, 'F', 'M'],\n",
    "    'income': [50000, 60000, None, None, 70000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 1: Visualize missing data using heatmap\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title('Missing Data Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Step 2: Identify patterns in missing data\n",
    "missing_summary = df.isnull().sum()\n",
    "print(\"Missing Values per Column:\\n\", missing_summary)\n",
    "\n",
    "# Optional: Visualize missing value counts as a bar plot\n",
    "missing_summary.plot(kind='bar')\n",
    "plt.title('Count of Missing Values per Column')\n",
    "plt.ylabel('Number of Missing Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Integrate Automated Data Quality Checks\n",
    "**Description**: Integrate automated data quality checks using the Great Expectations library for a dataset.\n",
    "\n",
    "**Steps**:\n",
    "1. Install and initialize Great Expectations.\n",
    "2. Set up Great Expectations.\n",
    "3. Add further checks and validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code from here\n",
    "# Step 1: Install Great Expectations (run this in your shell/terminal)\n",
    "# !pip install great_expectations\n",
    "\n",
    "# Step 2: Initialize Great Expectations and setup context\n",
    "import great_expectations as ge\n",
    "from great_expectations.core.batch import BatchRequest\n",
    "\n",
    "# Initialize Data Context (in current directory)\n",
    "context = ge.data_context.DataContext()\n",
    "\n",
    "# Step 3: Create an Expectation Suite\n",
    "suite_name = \"my_data_quality_suite\"\n",
    "suite = context.create_expectation_suite(suite_name, overwrite_existing=True)\n",
    "\n",
    "# Load sample data (e.g., CSV)\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    \"age\": [25, 30, 35, None, 40],\n",
    "    \"gender\": [\"M\", \"F\", \"F\", \"M\", None],\n",
    "    \"income\": [50000, 60000, None, 45000, 70000]\n",
    "})\n",
    "\n",
    "# Save dataset to CSV for GE batch request usage\n",
    "data_path = \"sample_data.csv\"\n",
    "df.to_csv(data_path, index=False)\n",
    "\n",
    "# Add a datasource for filesystem csv (only needed once)\n",
    "datasource_config = {\n",
    "    \"name\": \"my_datasource\",\n",
    "    \"class_name\": \"Datasource\",\n",
    "    \"execution_engine\": {\"class_name\": \"PandasExecutionEngine\"},\n",
    "    \"data_connectors\": {\n",
    "        \"default_runtime_data_connector_name\": {\n",
    "            \"class_name\": \"RuntimeDataConnector\",\n",
    "            \"batch_identifiers\": [\"default_identifier_name\"],\n",
    "        }\n",
    "    },\n",
    "}\n",
    "context.add_datasource(**datasource_config)\n",
    "\n",
    "# Create a batch request with the CSV file\n",
    "batch_request = {\n",
    "    \"datasource_name\": \"my_datasource\",\n",
    "    \"data_connector_name\": \"default_runtime_data_connector_name\",\n",
    "    \"data_asset_name\": \"sample_data_asset\",\n",
    "    \"runtime_parameters\": {\"batch_data\": df},\n",
    "    \"batch_identifiers\": {\"default_identifier_name\": \"default_identifier\"},\n",
    "}\n",
    "\n",
    "# Step 4: Add expectations (checks)\n",
    "validator = context.get_validator(batch_request=batch_request, expectation_suite_name=suite_name)\n",
    "\n",
    "# Check for no missing values in 'age' column\n",
    "validator.expect_column_values_to_not_be_null(\"age\")\n",
    "\n",
    "# Check for 'gender' to have values in allowed set\n",
    "validator.expect_column_values_to_be_in_set(\"gender\", [\"M\", \"F\"])\n",
    "\n",
    "# Check for 'income' to be non-null\n",
    "validator.expect_column_values_to_not_be_null(\"income\")\n",
    "\n",
    "# Save the expectations suite\n",
    "validator.save_expectation_suite()\n",
    "\n",
    "# Step 5: Validate the data and print results\n",
    "results = validator.validate()\n",
    "print(results)\n",
    "\n",
    "# Optionally, you can store or visualize the validation results through Great Expectations UI or reports.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
