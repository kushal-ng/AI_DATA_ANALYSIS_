{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Deduplication using Clustering\n",
    "**Objective**: Learn and implement data deduplication techniques.\n",
    "\n",
    "**Task**: Deduplication Using K-means Clustering\n",
    "\n",
    "**Steps**:\n",
    "1. Data Set: Download a dataset containing duplicate customer records.\n",
    "2. Preprocess: Standardize the data to ensure better clustering.\n",
    "3. Apply K-means: Use K-means clustering to find and group similar customer records.\n",
    "4. Identify Duplicates: Identify and remove duplicates within clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code from here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "import random\n",
    "\n",
    "# Step 1: Simulate a dataset with duplicate customer records\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank'],\n",
    "    'age': [25, 30, 35, 25, 30, 35, 40, 45, 50],\n",
    "    'income': [50000, 60000, 70000, 50500, 60200, 69800, 80000, 85000, 90000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 2: Preprocess by encoding categorical data and standardizing numerical data\n",
    "df_encoded = pd.get_dummies(df[['name']])\n",
    "df_features = pd.concat([df[['age', 'income']], df_encoded], axis=1)\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df_features)\n",
    "\n",
    "# Step 3: Apply K-means clustering\n",
    "kmeans = KMeans(n_clusters=6, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(scaled_features)\n",
    "\n",
    "# Step 4: Identify duplicates within clusters\n",
    "duplicates = []\n",
    "for cluster_id in df['cluster'].unique():\n",
    "    cluster_data = df[df['cluster'] == cluster_id]\n",
    "    if len(cluster_data) > 1:\n",
    "        indices, _ = pairwise_distances_argmin_min(cluster_data[['age', 'income']], \n",
    "                                                   [cluster_data[['age', 'income']].mean()])\n",
    "        representatives = cluster_data.iloc[indices].index[0]\n",
    "        cluster_duplicates = cluster_data.drop(index=representatives).index.tolist()\n",
    "        duplicates.extend(cluster_duplicates)\n",
    "\n",
    "dedup_df = df.drop(index=duplicates).reset_index(drop=True)\n",
    "\n",
    "print(\"Original records:\")\n",
    "print(df[['name', 'age', 'income', 'cluster']])\n",
    "print(\"\\nDeduplicated records:\")\n",
    "print(dedup_df[['name', 'age', 'income']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
