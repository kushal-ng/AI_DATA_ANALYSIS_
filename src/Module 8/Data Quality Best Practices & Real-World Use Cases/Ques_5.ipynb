{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI/ML â€“ Improving Model Performance with Clean Data\n",
    "\n",
    "**Task 1**: Data Preprocessing for Models\n",
    "\n",
    "**Objective**: Enhance data quality for better AI/ML outcomes.\n",
    "\n",
    "**Steps**:\n",
    "1. Choose a dataset for training an AI/ML model.\n",
    "2. Identify common data issues like null values, redundant features, or noisydata.\n",
    "3. Apply preprocessing methods such as imputation, normalization, or feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Sample dataset with common data issues\n",
    "data = {\n",
    "    'age': [25, 30, None, 22, 40, None, 35],\n",
    "    'income': [50000, 60000, 55000, None, 80000, 75000, None],\n",
    "    'gender': ['M', 'F', 'F', 'M', 'M', 'F', 'M'],\n",
    "    'education_level': ['Bachelors', 'Masters', 'PhD', 'Bachelors', None, 'Masters', 'PhD'],\n",
    "    'redundant_feature': [1, 1, 1, 1, 1, 1, 1]  # This feature has no variance and is redundant\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Drop redundant feature\n",
    "df = df.drop(columns=['redundant_feature'])\n",
    "\n",
    "# Handle missing numerical values with mean imputation\n",
    "num_cols = ['age', 'income']\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df[num_cols] = imputer.fit_transform(df[num_cols])\n",
    "\n",
    "# Handle missing categorical values with most frequent imputation\n",
    "cat_cols = ['education_level']\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[cat_cols] = cat_imputer.fit_transform(df[cat_cols])\n",
    "\n",
    "# Encode categorical variables (one-hot encoding for simplicity)\n",
    "df = pd.get_dummies(df, columns=['gender', 'education_level'], drop_first=True)\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2**: Evaluate Model Performance\n",
    "\n",
    "**Objective**: Assess the impact of data quality improvements on model performance.\n",
    "\n",
    "**Steps**:\n",
    "1. Train a simple ML model with and without preprocessing.\n",
    "2. Analyze and compare model performance metrics to evaluate the impact of data quality strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Sample dataset with missing and noisy data\n",
    "data = {\n",
    "    'age': [25, 30, None, 22, 40, None, 35, 28, 32, 31],\n",
    "    'income': [50000, 60000, 55000, None, 80000, 75000, None, 62000, 58000, 61000],\n",
    "    'gender': ['M', 'F', 'F', 'M', 'M', 'F', 'M', 'F', 'F', 'M'],\n",
    "    'education_level': ['Bachelors', 'Masters', 'PhD', 'Bachelors', None, 'Masters', 'PhD', 'Bachelors', 'Masters', 'PhD'],\n",
    "    'target': [0, 1, 0, 1, 0, 1, 0, 1, 1, 0]  # Binary classification target\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "\n",
    "# Split original data (without preprocessing)\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Model training and evaluation on raw data (handle missing by dropping rows here for simplicity)\n",
    "X_train_raw_clean = X_train_raw.dropna()\n",
    "y_train_raw_clean = y_train.loc[X_train_raw_clean.index]\n",
    "X_test_raw_clean = X_test_raw.dropna()\n",
    "y_test_raw_clean = y_test.loc[X_test_raw_clean.index]\n",
    "\n",
    "# Convert categorical to dummy variables for raw data\n",
    "X_train_raw_enc = pd.get_dummies(X_train_raw_clean, drop_first=True)\n",
    "X_test_raw_enc = pd.get_dummies(X_test_raw_clean, drop_first=True)\n",
    "\n",
    "# Align columns (in case some categories are missing in test or train)\n",
    "X_test_raw_enc = X_test_raw_enc.reindex(columns=X_train_raw_enc.columns, fill_value=0)\n",
    "\n",
    "model_raw = LogisticRegression(max_iter=1000)\n",
    "model_raw.fit(X_train_raw_enc, y_train_raw_clean)\n",
    "y_pred_raw = model_raw.predict(X_test_raw_enc)\n",
    "accuracy_raw = accuracy_score(y_test_raw_clean, y_pred_raw)\n",
    "\n",
    "# Preprocessing pipeline on full data\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Impute numerical columns\n",
    "num_cols = ['age', 'income']\n",
    "imputer_num = SimpleImputer(strategy='mean')\n",
    "df_processed[num_cols] = imputer_num.fit_transform(df_processed[num_cols])\n",
    "\n",
    "# Impute categorical column\n",
    "cat_cols = ['education_level']\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "df_processed[cat_cols] = imputer_cat.fit_transform(df_processed[cat_cols])\n",
    "\n",
    "# Encode categorical variables\n",
    "df_processed = pd.get_dummies(df_processed, columns=['gender', 'education_level'], drop_first=True)\n",
    "\n",
    "# Scale numerical columns\n",
    "scaler = StandardScaler()\n",
    "df_processed[num_cols] = scaler.fit_transform(df_processed[num_cols])\n",
    "\n",
    "X_processed = df_processed.drop(columns=['target'])\n",
    "y_processed = df_processed['target']\n",
    "\n",
    "X_train_proc, X_test_proc, y_train_proc, y_test_proc = train_test_split(X_processed, y_processed, test_size=0.3, random_state=42)\n",
    "\n",
    "model_proc = LogisticRegression(max_iter=1000)\n",
    "model_proc.fit(X_train_proc, y_train_proc)\n",
    "y_pred_proc = model_proc.predict(X_test_proc)\n",
    "accuracy_proc = accuracy_score(y_test_proc, y_pred_proc)\n",
    "\n",
    "print(f\"Accuracy without preprocessing: {accuracy_raw:.3f}\")\n",
    "print(f\"Accuracy with preprocessing: {accuracy_proc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
